{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5492ab92",
   "metadata": {},
   "source": [
    "# Building a Neural Network Classifier in PyTorch\n",
    "\n",
    "This tutorial walks you through building a basic neural network using **PyTorch's `nn.Module`**.  \n",
    "We use the **Breast Cancer Wisconsin dataset** to perform binary classification.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31caca88",
   "metadata": {},
   "source": [
    "### 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ab1239b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bf1ab3",
   "metadata": {},
   "source": [
    "### 2. Load and Preprocess the Dataset\n",
    "\n",
    "We load the dataset, standardize the features, split into training and testing sets, and convert the data to PyTorch tensors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "313a45b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8335e8c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33           184.60      2019.0   \n",
       "1                 0.05667  ...          23.41           158.80      1956.0   \n",
       "2                 0.05999  ...          25.53           152.50      1709.0   \n",
       "3                 0.09744  ...          26.50            98.87       567.7   \n",
       "4                 0.05883  ...          16.67           152.20      1575.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  target  \n",
       "0          0.4601                  0.11890       0  \n",
       "1          0.2750                  0.08902       0  \n",
       "2          0.3613                  0.08758       0  \n",
       "3          0.6638                  0.17300       0  \n",
       "4          0.2364                  0.07678       0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame from the data\n",
    "df = pd.DataFrame(data=data.data, columns=data.feature_names)\n",
    "\n",
    "# Add the target column\n",
    "df['target'] = data.target\n",
    "\n",
    "# Optional: Display the first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd4e7eb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 31)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3527ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(455, 30) (114, 30) (455,) (114,)\n"
     ]
    }
   ],
   "source": [
    "# Separate features and target\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "\n",
    "# Split the dataset: 80% train, 20% test (you can adjust the test_size as needed)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Optional: Display the shapes of the splits\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eefae123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'> <class 'pandas.core.frame.DataFrame'> <class 'pandas.core.series.Series'> <class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train), type(X_test), type(y_train), type(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a22dc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features (mean=0, std=1)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8014871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.to_numpy(), dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.to_numpy(), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39303c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> <class 'torch.Tensor'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train_tensor), type(X_test_tensor), type(y_train_tensor), type(y_test_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a93c4d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32 torch.float32 torch.float32 torch.float32\n"
     ]
    }
   ],
   "source": [
    "print(X_train_tensor.dtype, X_test_tensor.dtype, y_train_tensor.dtype, y_test_tensor.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ee6726",
   "metadata": {},
   "source": [
    "### 3. Creating Custom Dataset using Dataset & DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47be7f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, features, targets):\n",
    "        self.features = features\n",
    "        self.targets = targets\n",
    "    \n",
    "    def __len__(self):\n",
    "        # Return total number of samples\n",
    "        return len(self.features)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # Return one sample of data and label\n",
    "        return self.features[index], self.targets[index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79e90fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = CustomDataset(X_test_tensor, y_test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f86db55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.4976,  0.6137, -0.4981, -0.5310, -0.5769, -0.1749, -0.3622, -0.2849,\n",
       "          0.4335,  0.1782, -0.3684,  0.5531, -0.3167, -0.4052,  0.0403, -0.0380,\n",
       "         -0.1804,  0.1648, -0.1217,  0.2308, -0.5004,  0.8194, -0.4692, -0.5331,\n",
       "         -0.0491, -0.0416, -0.1491,  0.0968,  0.1062,  0.4904]),\n",
       " tensor(1.))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a895db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ac1298",
   "metadata": {},
   "source": [
    "### 4. Define the Model Class\n",
    "\n",
    "We define a neural network using PyTorch's `nn.Module` with the following architecture:\n",
    "- Linear layer with 3 hidden units\n",
    "- ReLU activation\n",
    "- Output layer with sigmoid activation for binary classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f999607a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySimpleNN(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(num_features, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(3, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8ccfc1",
   "metadata": {},
   "source": [
    "### 5. Set Training Parameters\n",
    "We define the hyperparameters and loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2da5f8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = MySimpleNN(X_train_tensor.shape[1])\n",
    "# define epochs\n",
    "epochs = 25\n",
    "# define loss function\n",
    "loss_function = nn.BCELoss()\n",
    "# define learning_rate\n",
    "learning_rate = 0.1\n",
    "# define optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52430a49",
   "metadata": {},
   "source": [
    "### 6. Train the Model\n",
    "We train the model using the SGD optimizer and track the loss at each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc2afe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 0.31420519948005676\n",
      "Epoch: 2, Loss: 0.0004274158854968846\n",
      "Epoch: 3, Loss: 0.0023832565639168024\n",
      "Epoch: 4, Loss: 0.0012654215097427368\n",
      "Epoch: 5, Loss: 0.011919582262635231\n",
      "Epoch: 6, Loss: 0.13620533049106598\n",
      "Epoch: 7, Loss: 0.03152069076895714\n",
      "Epoch: 8, Loss: 0.01760205067694187\n",
      "Epoch: 9, Loss: 0.00961923599243164\n",
      "Epoch: 10, Loss: 0.029511677101254463\n",
      "Epoch: 11, Loss: 0.030012700706720352\n",
      "Epoch: 12, Loss: 0.1285409778356552\n",
      "Epoch: 13, Loss: 0.0023159205447882414\n",
      "Epoch: 14, Loss: 0.00015762599650770426\n",
      "Epoch: 15, Loss: 0.009274658747017384\n",
      "Epoch: 16, Loss: 0.004612325690686703\n",
      "Epoch: 17, Loss: 0.01296616904437542\n",
      "Epoch: 18, Loss: 0.00548334838822484\n",
      "Epoch: 19, Loss: 0.03049200214445591\n",
      "Epoch: 20, Loss: 0.007991793565452099\n",
      "Epoch: 21, Loss: 0.00716188782826066\n",
      "Epoch: 22, Loss: 0.009107222780585289\n",
      "Epoch: 23, Loss: 0.025988789275288582\n",
      "Epoch: 24, Loss: 0.007622851990163326\n",
      "Epoch: 25, Loss: 0.0031806137412786484\n"
     ]
    }
   ],
   "source": [
    "# define loop\n",
    "for epoch in range(epochs):\n",
    "  for batch_features, batch_labels in train_loader:\n",
    "\n",
    "    # forward pass\n",
    "    y_pred = model(batch_features)\n",
    "\n",
    "    # loss calculate\n",
    "    loss = loss_function(y_pred, batch_labels.view(-1,1))\n",
    "\n",
    "    # clear gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # backward pass\n",
    "    loss.backward()\n",
    "\n",
    "    # parameters update\n",
    "    optimizer.step()\n",
    "\n",
    "  # print loss in each epoch\n",
    "  print(f'Epoch: {epoch + 1}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3880e05a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters <bound method Module.parameters of Sequential(\n",
      "  (0): Linear(in_features=30, out_features=3, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=3, out_features=1, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")>\n",
      "Linear(in_features=30, out_features=3, bias=True)\n",
      "------------------------------\n",
      "Weights: Parameter containing:\n",
      "tensor([[ 0.2369,  0.2718,  0.4842,  0.4907, -0.0364,  0.1770,  0.3463,  0.4439,\n",
      "         -0.1423, -0.2371,  0.1677, -0.2378,  0.2136,  0.3020,  0.2010, -0.1934,\n",
      "          0.1740,  0.0628, -0.0814, -0.3458,  0.5118,  0.6636,  0.5081,  0.2833,\n",
      "          0.5597,  0.0163,  0.4181,  0.5547,  0.5729, -0.0520],\n",
      "        [ 0.0583,  0.2333,  0.1062,  0.2185,  0.2838, -0.0287,  0.2530,  0.0957,\n",
      "         -0.0218, -0.0712,  0.3551,  0.0741,  0.2575,  0.1055, -0.1583, -0.2673,\n",
      "         -0.0390,  0.2479,  0.0711, -0.2443,  0.1495,  0.1102,  0.1891,  0.1000,\n",
      "          0.2266, -0.0350,  0.0491,  0.1541,  0.3704,  0.1460],\n",
      "        [-0.0622, -0.0241, -0.1114, -0.1618, -0.0120,  0.3609, -0.3042, -0.4722,\n",
      "          0.0892, -0.0578, -0.4988,  0.0372, -0.5560, -0.4279, -0.0291,  0.5538,\n",
      "         -0.0951,  0.0077,  0.3095,  0.2683, -0.3971, -0.7085, -0.2846, -0.4252,\n",
      "         -0.3516,  0.1631, -0.3232, -0.3263, -0.4592,  0.0539]],\n",
      "       requires_grad=True)\n",
      "------------------------------\n",
      "Bias: Parameter containing:\n",
      "tensor([0.4294, 0.1120, 0.8785], requires_grad=True)\n",
      "Linear(in_features=3, out_features=1, bias=True)\n",
      "------------------------------\n",
      "Weights: Parameter containing:\n",
      "tensor([[-1.8563, -0.8573,  1.8971]], requires_grad=True)\n",
      "------------------------------\n",
      "Bias: Parameter containing:\n",
      "tensor([0.3514], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(\"Parameters\", model.network.parameters)\n",
    "for layer in model.network:\n",
    "    if isinstance(layer, nn.Linear):\n",
    "        print(layer)\n",
    "        print(\"-\"*30)\n",
    "        print(\"Weights:\", layer.weight)\n",
    "        print(\"-\"*30)\n",
    "        print(\"Bias:\", layer.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7e0fb8",
   "metadata": {},
   "source": [
    "### 6. Evaluate the Model\n",
    "We test the model on unseen data and calculate accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0217d5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9844\n"
     ]
    }
   ],
   "source": [
    "# Model evaluation using test_loader\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "accuracy_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_features, batch_labels in test_loader:\n",
    "        # Forward pass\n",
    "        y_pred = model(batch_features)\n",
    "        y_pred = (y_pred > 0.5).float()  # Convert probabilities to binary predictions\n",
    "\n",
    "        # Calculate accuracy for the current batch\n",
    "        batch_accuracy = (y_pred.view(-1) == batch_labels).float().mean().item()\n",
    "        accuracy_list.append(batch_accuracy)\n",
    "\n",
    "# Calculate overall accuracy\n",
    "overall_accuracy = sum(accuracy_list) / len(accuracy_list)\n",
    "print(f'Accuracy: {overall_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc40e88",
   "metadata": {},
   "source": [
    "###  Conclusion\n",
    "We built and trained a simple neural network using PyTorch.\n",
    "\n",
    "- We used `nn.Sequential` for fast model definition.\n",
    "- Training was done with `BCELoss` and `SGD`.\n",
    "- We used dataaset class and dataloader for creating custom data.\n",
    "- We calculated accuracy for binary classification from each batch and calculated mean accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa521e2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daef830a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
