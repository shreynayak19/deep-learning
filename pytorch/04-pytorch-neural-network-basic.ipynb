{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e70722f",
   "metadata": {},
   "source": [
    "# Logistic Regression from Scratch with PyTorch \n",
    "\n",
    "This tutorial demonstrates how to implement logistic regression from scratch using PyTorch.  \n",
    "We use the Breast Cancer Wisconsin dataset to train and evaluate our model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f083f41a",
   "metadata": {},
   "source": [
    "### 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "67690039",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a41c32",
   "metadata": {},
   "source": [
    "### 2. Load and Preprocess the Dataset\n",
    "\n",
    "We begin by loading the Breast Cancer dataset, converting it into a DataFrame, and preparing it for training. This includes:\n",
    "- Splitting into features and labels\n",
    "- Splitting into train/test sets\n",
    "- Standardizing the feature values\n",
    "- Converting everything into PyTorch tensors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9cee4cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bc83cd1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33           184.60      2019.0   \n",
       "1                 0.05667  ...          23.41           158.80      1956.0   \n",
       "2                 0.05999  ...          25.53           152.50      1709.0   \n",
       "3                 0.09744  ...          26.50            98.87       567.7   \n",
       "4                 0.05883  ...          16.67           152.20      1575.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  target  \n",
       "0          0.4601                  0.11890       0  \n",
       "1          0.2750                  0.08902       0  \n",
       "2          0.3613                  0.08758       0  \n",
       "3          0.6638                  0.17300       0  \n",
       "4          0.2364                  0.07678       0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame from the data\n",
    "df = pd.DataFrame(data=data.data, columns=data.feature_names)\n",
    "\n",
    "# Add the target column\n",
    "df['target'] = data.target\n",
    "\n",
    "# Optional: Display the first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0eda6ad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 31)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e0f371e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(455, 30) (114, 30) (455,) (114,)\n"
     ]
    }
   ],
   "source": [
    "# Separate features and target\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "\n",
    "# Split the dataset: 80% train, 20% test (you can adjust the test_size as needed)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Optional: Display the shapes of the splits\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a5b317ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'> <class 'pandas.core.frame.DataFrame'> <class 'pandas.core.series.Series'> <class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train), type(X_test), type(y_train), type(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "11660274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features (mean=0, std=1)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f6ed16f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.to_numpy(), dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.to_numpy(), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2d5b8733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> <class 'torch.Tensor'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train_tensor), type(X_test_tensor), type(y_train_tensor), type(y_test_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6cce87cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32 torch.float32 torch.float32 torch.float32\n"
     ]
    }
   ],
   "source": [
    "print(X_train_tensor.dtype, X_test_tensor.dtype, y_train_tensor.dtype, y_test_tensor.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dace860f",
   "metadata": {},
   "source": [
    "### 3. Define the Model Class\n",
    "\n",
    "We define a class `MySimpleNN` that performs logistic regression using PyTorch tensors.\n",
    "\n",
    "Key components:\n",
    "- Manual weight and bias initialization\n",
    "- Sigmoid activation\n",
    "- Binary cross-entropy loss calculation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ff8358f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySimpleNN:\n",
    "    def __init__(self, X):\n",
    "        # Initialize weights and bias with correct shape\n",
    "        self.weights = torch.rand(X.shape[1], 1, dtype=torch.float32, requires_grad=True)\n",
    "        self.bias = torch.zeros(1, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "    def forward(self, X):\n",
    "        # Linear transformation + sigmoid activation\n",
    "        z = torch.matmul(X, self.weights) + self.bias\n",
    "        # Sigmoid Activation Function\n",
    "        y_pred = torch.sigmoid(z)\n",
    "        return y_pred\n",
    "\n",
    "    def loss_function(self, y_pred, y_true):\n",
    "        # Clamp predictions to avoid log(0)\n",
    "        epsilon = 1e-7\n",
    "        y_pred = torch.clamp(y_pred, epsilon, 1 - epsilon)\n",
    "\n",
    "        # Binary cross-entropy loss\n",
    "        loss = -(y_true * torch.log(y_pred) + (1 - y_true) * torch.log(1 - y_pred)).mean()\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ac682b",
   "metadata": {},
   "source": [
    "### 4. Training Loop\n",
    "\n",
    "We train the model using a simple gradient descent approach.\n",
    "\n",
    "Each step includes:\n",
    "- Forward pass\n",
    "- Loss calculation\n",
    "- Backward pass\n",
    "- Manual weight update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e3140314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 3.5468\n",
      "Epoch 2, Loss: 3.3806\n",
      "Epoch 3, Loss: 3.2106\n",
      "Epoch 4, Loss: 3.0389\n",
      "Epoch 5, Loss: 2.8615\n",
      "Epoch 6, Loss: 2.6850\n",
      "Epoch 7, Loss: 2.5089\n",
      "Epoch 8, Loss: 2.3333\n",
      "Epoch 9, Loss: 2.1586\n",
      "Epoch 10, Loss: 1.9879\n",
      "Epoch 11, Loss: 1.8198\n",
      "Epoch 12, Loss: 1.6570\n",
      "Epoch 13, Loss: 1.5031\n",
      "Epoch 14, Loss: 1.3627\n",
      "Epoch 15, Loss: 1.2357\n",
      "Epoch 16, Loss: 1.1263\n",
      "Epoch 17, Loss: 1.0350\n",
      "Epoch 18, Loss: 0.9615\n",
      "Epoch 19, Loss: 0.9043\n",
      "Epoch 20, Loss: 0.8611\n",
      "Epoch 21, Loss: 0.8290\n",
      "Epoch 22, Loss: 0.8052\n",
      "Epoch 23, Loss: 0.7875\n",
      "Epoch 24, Loss: 0.7739\n",
      "Epoch 25, Loss: 0.7632\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 0.1\n",
    "epochs = 25\n",
    "\n",
    "# Initialize the model\n",
    "model = MySimpleNN(X_train_tensor)\n",
    "\n",
    "# Training process\n",
    "for epoch in range(epochs):\n",
    "    # Forward pass\n",
    "    y_pred = model.forward(X_train_tensor)\n",
    "\n",
    "    # Compute loss\n",
    "    loss = model.loss_function(y_pred, y_train_tensor)\n",
    "\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "\n",
    "    # Update weights and bias manually\n",
    "    with torch.no_grad():\n",
    "        model.weights -= learning_rate * model.weights.grad\n",
    "        model.bias -= learning_rate * model.bias.grad\n",
    "\n",
    "        # Zero gradients for next iteration\n",
    "        model.weights.grad.zero_()\n",
    "        model.bias.grad.zero_()\n",
    "\n",
    "    # Print loss per epoch\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "921d97a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3923], requires_grad=True)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48baec8d",
   "metadata": {},
   "source": [
    "### 5. Model Evaluation\n",
    "\n",
    "We now evaluate the model on the test set.\n",
    "\n",
    "We'll:\n",
    "- Use the model to generate predictions\n",
    "- Apply a confidence threshold\n",
    "- Compute accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d0f638bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 53.88%\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "  # Predict on test data\n",
    "  y_pred = model.forward(X_test_tensor)\n",
    "\n",
    "  # Convert probabilities to binary predictions\n",
    "  y_pred_label = (y_pred > 0.5).float()  # using 0.9 threshold for high confidence\n",
    "\n",
    "  # Calculate accuracy\n",
    "  accuracy = (y_pred_label == y_test_tensor).float().mean()\n",
    "  print(f\"Test Accuracy: {accuracy.item() * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b953e410",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "We successfully built and trained a logistic regression model **from scratch** using PyTorch.\n",
    "\n",
    "- We manually managed weights, bias, and gradients.\n",
    "- We used the binary cross-entropy loss function.\n",
    "- We achieved a decent accuracy even with a high-confidence threshold.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
